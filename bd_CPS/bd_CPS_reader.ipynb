{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_reader.ipynb\n",
    "\n",
    "April 16, 2019\n",
    "\n",
    "Contact: Brian Dew, @bd_econ\n",
    "\n",
    "Requires: `cps_basic_dd.pkl` which is generated by bd_CPS_dd.ipynb\n",
    "\n",
    "-----\n",
    "\n",
    "See [readme](https://github.com/bdecon/econ_data/tree/master/bd_CPS) for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:42.160277Z",
     "start_time": "2024-07-25T11:34:41.609138Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:43.281543Z",
     "iopub.status.busy": "2025-01-17T13:22:43.281152Z",
     "iopub.status.idle": "2025-01-17T13:22:43.985571Z",
     "shell.execute_reply": "2025-01-17T13:22:43.985053Z",
     "shell.execute_reply.started": "2025-01-17T13:22:43.281502Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.2.2\n",
      "numpy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "import numpy as np\n",
    "print('numpy:', np.__version__)\n",
    "import struct\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Statsmodels used to impute hours worked on first job\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Map codes for country of birth to country/area names\n",
    "from bd_CPS_details import COB1994Map, COB2007Map, AsianMap, EducDTMap, DropVars, INDMMap\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.433483Z",
     "start_time": "2024-07-25T11:34:42.161899Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:43.986335Z",
     "iopub.status.busy": "2025-01-17T13:22:43.986038Z",
     "iopub.status.idle": "2025-01-17T13:22:46.387830Z",
     "shell.execute_reply": "2025-01-17T13:22:46.387321Z",
     "shell.execute_reply.started": "2025-01-17T13:22:43.986320Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))\n",
    "data_path = '/home/brian/Documents/CPS/data/'\n",
    "data_files = os.listdir(data_path)\n",
    "\n",
    "# Consumer Price Index (retrieve using bd_CPS_cpi)\n",
    "cpi = pd.read_csv('clean/cpi.csv', index_col=[0], parse_dates=True)\n",
    "\n",
    "# Federal minimum wage from DOL:\n",
    "min_wage = [('1981-01-01', '1990-04-01', 3.35),\n",
    "            ('1990-04-01', '1991-04-01', 3.80),\n",
    "            ('1991-04-01', '1996-10-01', 4.25),\n",
    "            ('1996-10-01', '1997-09-01', 4.75),\n",
    "            ('1997-09-01', '2007-07-24', 5.15),\n",
    "            ('2007-07-24', '2008-07-24', 5.85),\n",
    "            ('2008-07-24', '2009-07-24', 6.55),\n",
    "            ('2009-07-24', '2025-12-01', 7.25)]\n",
    "\n",
    "min_wage = [(pd.to_datetime(i[0]), pd.to_datetime(i[1]), i[2])\n",
    "            for i in min_wage]\n",
    "\n",
    "# Unique ID list\n",
    "ids_file = 'CPS_unique_ids.pkl'\n",
    "if os.path.isfile(ids_file):\n",
    "    cps_ids_full = pickle.load(open(ids_file, 'rb'))\n",
    "\n",
    "ids_file = 'CPSID_89-93.pkl'\n",
    "if os.path.isfile(ids_file):\n",
    "    cps_ids_full_early = pickle.load(open(ids_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.439196Z",
     "start_time": "2024-07-25T11:34:44.434649Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.389261Z",
     "iopub.status.busy": "2025-01-17T13:22:46.389087Z",
     "iopub.status.idle": "2025-01-17T13:22:46.393337Z",
     "shell.execute_reply": "2025-01-17T13:22:46.392870Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.389246Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def id2_gen(np_mo):\n",
    "    \"\"\"Create HRHHID2 for pre May 2004 data\"\"\"\n",
    "    hrsample = [x[1:3] for x in np_mo['HRSAMPLE']]\n",
    "    hrsersuf = [x.strip() for x in np_mo['HRSERSUF']]\n",
    "    sersuf_d = {a: str(ord(a.lower()) - 96).zfill(2) for a in set(hrsersuf)\n",
    "            if a in list(string.ascii_letters)}\n",
    "    sersuf_d.update({'-1': '00', '-1.0': '00', '0': '00'})\n",
    "    sersuf = list(map(sersuf_d.get, hrsersuf))\n",
    "    np_mo.loc[np_mo['HUHHNUM'] < 0, 'HUHHNUM'] = 0\n",
    "    huhhnum = np_mo['HUHHNUM'].astype('U1')\n",
    "    \n",
    "    id2 = [''.join(i) for i in zip(hrsample, sersuf, huhhnum)]\n",
    "\n",
    "    return(np.array(id2, dtype='uint32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.448919Z",
     "start_time": "2024-07-25T11:34:44.441276Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.393956Z",
     "iopub.status.busy": "2025-01-17T13:22:46.393793Z",
     "iopub.status.idle": "2025-01-17T13:22:46.416883Z",
     "shell.execute_reply": "2025-01-17T13:22:46.415397Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.393941Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def data_file_reader(file, unpacker, dtypes, ws, we):\n",
    "    \n",
    "    # If person weight > 0, unpack the raw file\n",
    "    if file == 'mar04pub.dat':\n",
    "        data = [unpacker(row) for row in open(file, 'rb')\n",
    "                if b'**' not in row and row[ws:we].strip() > b'0']\n",
    "    elif file[3:5] in ['94', '95']:\n",
    "        data = [unpacker(row.replace(b'\\x00\\x00', b'-1')) \n",
    "                for row in open(file, 'rb')\n",
    "                if row[ws:we].strip() > b'0']\n",
    "    elif file[3:5] in ['23']:\n",
    "        data = [unpacker(row.replace(b'--', b'0-')) \n",
    "                for row in open(file, 'rb')\n",
    "                if row[ws:we].strip() > b'0']\n",
    "    else:\n",
    "        data = [unpacker(row) for row in open(file, 'rb') \n",
    "                if row[ws:we].strip() > b'0']\n",
    "        \n",
    "    # Convert to dataframe using specified weights\n",
    "    df = pd.DataFrame(np.array(data, dtype=dtypes))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.486453Z",
     "start_time": "2024-07-25T11:34:44.450247Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.419384Z",
     "iopub.status.busy": "2025-01-17T13:22:46.418900Z",
     "iopub.status.idle": "2025-01-17T13:22:46.483097Z",
     "shell.execute_reply": "2025-01-17T13:22:46.482304Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.419337Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_all(df, maps, cpi_vals, date):\n",
    "    \n",
    "    # New variables to add\n",
    "    age = lambda x: np.where(x['PRTAGE'] > 80, 80, x['PRTAGE'])\n",
    "    female = lambda x: pd.Categorical(np.where(x['PESEX'] == 2, 1, 0))\n",
    "    state = lambda x: pd.Categorical(x['GESTFIPS'].map(maps['state']))\n",
    "    region = lambda x: x['STATE'].map(maps['region'])\n",
    "    educdt = lambda x: pd.Categorical(x['PEEDUCA'].map(EducDTMap))\n",
    "    educ = lambda x: pd.Categorical(x['PEEDUCA'].map(maps['educ']))\n",
    "    schenr = lambda x: pd.Categorical(\n",
    "        np.where(x['PESCHENR'] == 1, 1, \n",
    "        np.where(x['PESCHENR'] == 2, 0, None)))\n",
    "    married = lambda x: pd.Categorical(\n",
    "        np.where(x['PRMARSTA'].isin([1, 2, 3]), 1, 0))\n",
    "    wbhao = lambda x: pd.Categorical(\n",
    "        np.where(x['PRDTHSP'].isin(maps['hisp']), 'Hispanic', \n",
    "                 x['PRDTRACE'].map(maps['race'])))\n",
    "    wbao = lambda x: pd.Categorical(x['PRDTRACE'].map(maps['race']))\n",
    "    hispanic = lambda x: pd.Categorical(\n",
    "        np.where(x['PRDTHSP'].isin(maps['hisp']), 1, 0))\n",
    "    veteran = lambda x: pd.Categorical(\n",
    "        np.where(x['PEAFEVER'] == 1, 1, \n",
    "        np.where(x['PEAFEVER'] == 2, 0, None)))\n",
    "    forborn = lambda x: pd.Categorical(\n",
    "        np.where(x['PRCITSHP'].isin([4, 5]), 1, \n",
    "        np.where(x['PRCITSHP'].isin([1, 2, 3]), 0, None)))\n",
    "    citizen = lambda x: pd.Categorical(\n",
    "        np.where(x['PRCITSHP'].isin([1, 2, 3, 4]), 1, \n",
    "        np.where(x['PRCITSHP'].isin([5]), 0, None)))\n",
    "    indgrp =  lambda x: pd.Categorical(x['PRMJIND1'].map(maps['ind']))\n",
    "    manager = lambda x: np.where(x.PRDTOCC1 == 1, 1,\n",
    "                        np.where(x.PRDTOCC1 > 0, 0, None))\n",
    "    mjh = lambda x: pd.Categorical(\n",
    "        np.where(x['PRSJMJ']==2, 1, np.where(x['PRSJMJ']==1, 0, None)))\n",
    "    numjobs = lambda x: np.where(x.PEMJNUM > 1, x.PEMJNUM,\n",
    "        np.where((x.MJH == 0) & (x.LFS == \"Employed\"), 1, 0))\n",
    "    unemptype = lambda x: pd.Categorical(\n",
    "        np.where(x['PRUNTYPE'].isin([1, 2, 3]), 'Job Loser',\n",
    "        np.where(x['PRUNTYPE'] == 4, 'Job Leaver',\n",
    "        np.where(x['PRUNTYPE'] == 5, 'Re-entrant',\n",
    "        np.where(x['PRUNTYPE'] == 6, 'New Entrant', None)))))\n",
    "    layoff = lambda x: pd.Categorical(\n",
    "        np.where(x['PEMLR'] == 3, 'Layoff',\n",
    "        np.where(x['PEMLR'] == 4, 'Looking', None)))\n",
    "    ptecon = lambda x: pd.Categorical(\n",
    "        np.where(x['PRWKSTAT'].isin([3, 6]), 1, \n",
    "        np.where(x['PRWKSTAT'].between(2, 10), 0, None)))\n",
    "    uslft = lambda x: pd.Categorical(\n",
    "        np.where((x['PEHRFTPT'] == 1) | (x['PEHRUSL1'] >= 35), 1,\n",
    "        np.where(x['PEHRFTPT'] == 2, 0, \n",
    "        np.where(x['PEHRFTPT'] == 3, -4, None))))\n",
    "    workft = lambda x: pd.Categorical(\n",
    "        np.where(x['PRWKSTAT'].isin([2, 8, 9]), 1,\n",
    "        np.where(x['PRWKSTAT'].between(2, 10), 0, None)))\n",
    "    ftlf = lambda x: pd.Categorical(\n",
    "        np.where(x.PRFTLF == 1, 'Full-time',\n",
    "        np.where(x.PRFTLF == 2, 'Part-time', None)))\n",
    "    sameemp = lambda x: pd.Categorical(\n",
    "        np.where(x['PUIODP1'] == 1, 1,\n",
    "        np.where(x['PUIODP1'] == 2, 0, None)))\n",
    "    chduties = lambda x: pd.Categorical(\n",
    "        np.where(x['PUIODP2'] == 1, 1,\n",
    "        np.where(x['PUIODP2'] == 2, 0, None)))\n",
    "    sameact = lambda x: pd.Categorical(\n",
    "        np.where(x['PUIODP3'] == 1, 1,\n",
    "        np.where(x['PUIODP3'] == 2, 0, None)))\n",
    "    chjobact = lambda x: pd.Categorical(\n",
    "        np.where((x.PUIODP1 == 2) | (x.PUIODP2 == 1) | \n",
    "                 (x.PUIODP3 == 2), 1,\n",
    "        np.where((x.PUIODP1 == 1) | (x.PUIODP2 == 2) | \n",
    "                 (x.PUIODP3 == 1), 0, None)))\n",
    "    notatwork = lambda x: pd.Categorical(\n",
    "        np.where(x['PRWKSTAT'].isin([5,10]), 1,\n",
    "        np.where(x['PRWKSTAT'].between(1, 12), 0, None)))\n",
    "    lfs = lambda x: pd.Categorical(\n",
    "        np.where(x['PEMLR'].isin([1, 2]), 'Employed',\n",
    "        np.where(x['PEMLR'].isin([3, 4]), 'Unemployed',\n",
    "        np.where(x['PEMLR'].isin([5, 6, 7]), 'NILF', np.nan))))\n",
    "    cow1 = lambda x: pd.Categorical(\n",
    "        np.where(x['PEIO1COW'] == 1, 'Federal Government',\n",
    "        np.where(x['PEIO1COW'] == 2, 'State Government',\n",
    "        np.where(x['PEIO1COW'] == 3, 'Local Government',\n",
    "        np.where(x['PEIO1COW'].isin([4, 5]), 'Private',\n",
    "        np.where(x['PEIO1COW'] == 6, 'Self-employed Incorporated',\n",
    "        np.where(x['PEIO1COW'] == 7, 'Self-employed Unincorporated',\n",
    "        np.where(x['PEIO1COW'] == 8, 'Without Pay', None))))))))\n",
    "    cow2 = lambda x: pd.Categorical(\n",
    "        np.where(x['PEIO2COW'] == 1, 'Federal Government',\n",
    "        np.where(x['PEIO2COW'] == 2, 'State Government',\n",
    "        np.where(x['PEIO2COW'] == 3, 'Local Government',\n",
    "        np.where(x['PEIO2COW'].isin([4, 5]), 'Private',\n",
    "        np.where(x['PEIO2COW'] == 6, 'Self-employed Incorporated',\n",
    "        np.where(x['PEIO2COW'] == 7, 'Self-employed Unincorporated',\n",
    "        np.where(x['PEIO2COW'] == 8, 'Without Pay', None))))))))\n",
    "    nilfreason = lambda x: pd.Categorical(\n",
    "        np.where((x['PRWNTJOB']==2) & \n",
    "                 ((x['PEMLR']==6) | (x['PENLFACT'].isin([1, 2]))), \n",
    "                 'Disabled/Ill',\n",
    "        np.where((x['PRWNTJOB']==2) & (x['PENLFACT']==4), 'Family',\n",
    "        np.where((x['PRWNTJOB']==2) & ((x['PEMLR']==5) | (x['PENLFACT']==5)), \n",
    "                 'Retired',\n",
    "        np.where((x['PRWNTJOB']==2) & ((x['PENLFACT']==3) | (x['SCHENR']==1)), \n",
    "                 'School',\n",
    "        np.where((x['PRWNTJOB']==1) & (x['PEMLR'].isin([5,6,7])), 'Discouraged',\n",
    "        np.where(x['PEMLR'].isin([5, 6, 7]), 'Other', np.nan)))))))\n",
    "    nlffam = lambda x: pd.Categorical(\n",
    "        np.where(x.PENLFACT == 4, 1, \n",
    "        np.where(x.LFS == 'NILF', 0, None)))\n",
    "    paidhrly = lambda x: pd.Categorical(\n",
    "        np.where(x['PEERNHRY'] == 1, 1,\n",
    "        np.where(x['PEERNHRY'] == 2, 0, None)))\n",
    "    proxy = lambda x: pd.Categorical(\n",
    "        np.where(x['PUSLFPRX'] == 1, 'Self',\n",
    "        np.where(x['PUSLFPRX'] == 2, 'Proxy',\n",
    "        np.where(x['PUSLFPRX'] == 3, 'Both', None))))\n",
    "    dwtype = lambda x: pd.Categorical(\n",
    "        np.where(x.PRDISC == 1, 'Discouraged',\n",
    "        np.where(x.PRDISC == 2, 'Marginally Attached',\n",
    "        np.where(x.PRJOBSEA == 5, 'No Recent Search',\n",
    "        np.where(x.PRDISC == 3, 'Unavailable', None)))))\n",
    "    abstype = lambda x: pd.Categorical(\n",
    "        np.where((x.PRABSREA.isin([1, 11, 21, 31])) | \n",
    "                 (x.PEHRRSN3 == 4), 'Vacation', \n",
    "        np.where((x.PRABSREA.isin([2, 12, 22, 32])) | \n",
    "                 (x.PEHRRSN3 == 5), 'Sick',  \n",
    "        np.where((x.PRABSREA.isin([3, 13, 23, 33])) | \n",
    "                 (x.PEHRRSN3 == 7), 'Child Care', \n",
    "        np.where((x.PRABSREA.isin([4, 14, 24, 34])) | \n",
    "                 (x.PEHRRSN3 == 8), 'Other Family/Personal', \n",
    "        np.where(x.PRABSREA.isin([5, 15, 25, 35]), 'Maternity/Paternity',  \n",
    "        np.where((x.PRABSREA.isin([6, 16, 26, 36])) | \n",
    "                 (x.PEHRRSN3 == 9), 'Labor Dispute',  \n",
    "        np.where((x.PRABSREA.isin([7, 17, 27, 37])) |\n",
    "                 (x.PEHRRSN3 == 10), 'Weather',  \n",
    "        np.where((x.PRABSREA.isin([8, 18, 28, 38])) | \n",
    "                 (x.PEHRRSN3 == 11), 'School/Training',  \n",
    "        np.where((x.PRABSREA.isin([9, 19, 29, 39])) | \n",
    "                 (x.PEHRRSN3 == 12), 'Civic/Military',  \n",
    "        np.where((x.PRABSREA.isin([10, 20, 30, 40])) | \n",
    "                 (x.PEHRRSN3 == 13), 'Other',  \n",
    "        np.where(x.PEHRRSN3 == 6, 'Holiday', None))))))))))))\n",
    "    abspaid = lambda x: pd.Categorical(\n",
    "        np.where(x.PRABSREA.isin(list(range(1, 11)) + \n",
    "                                 list(range(21, 31))), 'Paid',\n",
    "        np.where(x.PRABSREA.isin(list(range(11, 21)) + \n",
    "                                 list(range(31, 41))), 'Unpaid', None)))\n",
    "    ptreason = lambda x: pd.Categorical(\n",
    "        np.where(x.ABSTYPE.notnull(), None, # Not defined for FT but absent\n",
    "        np.where(x.PRPTREA == 3, 'Job Started/Ended During Week',\n",
    "        np.where((x.PRPTREA.isin([1, 14])) | (x.PEHRRSN1 == 1), \n",
    "                 'Slack Work/Business Conditions',\n",
    "        np.where((x.PRPTREA == 15) | (x.PEHRRSN1 == 2), \n",
    "                 'Could Only Find PT Work',\n",
    "        np.where((x.PRPTREA.isin([2, 16])) | (x.PEHRRSN1 == 3), \n",
    "                 'Seasonal Work',\n",
    "        np.where((x.PRPTREA == 17) | (x.PEHRRSN1 == 4) | (x.PEHRRSN2 == 1),\n",
    "                 'Child Care Problems',\n",
    "        np.where((x.PRPTREA == 18) | (x.PEHRRSN1 == 5) | (x.PEHRRSN2 == 2), \n",
    "                 'Other Family/Personal Obligations',\n",
    "        np.where((x.PRPTREA == 19) | (x.PEHRRSN1 == 6) | (x.PEHRRSN2 == 3),\n",
    "                 'Health/Medical Limitations',\n",
    "        np.where((x.PRPTREA == 20) | (x.PEHRRSN1 == 7) | (x.PEHRRSN2 == 4), \n",
    "                 'School/Training',\n",
    "        np.where((x.PRPTREA == 21) | (x.PEHRRSN1 == 8) | (x.PEHRRSN2 == 5), \n",
    "                 'Retired/Earnings Limit',\n",
    "        np.where((x.PRPTREA == 22) | (x.PEHRRSN1 == 9) | (x.PEHRRSN2 == 6), \n",
    "                 'Workweek <35 Hours',\n",
    "        np.where((x.PRPTREA.isin([13, 23])) | (x.PEHRRSN1 == 10) | (x.PEHRRSN2 == 7), \n",
    "                 'Other', None)))))))))))))\n",
    "    wantft = lambda x: pd.Categorical(\n",
    "        np.where(x.PEHRWANT == 1, 1, np.where(x.PEHRWANT == 2, 0, None)))\n",
    "    jltype = lambda x: pd.Categorical(\n",
    "        np.where(x.PRUNTYPE == 1, 'Temporary Layoff', \n",
    "        np.where(x.PRUNTYPE == 2, 'Permanent Job Loss', \n",
    "        np.where(x.PRUNTYPE == 3, 'Temporary Job Ended', None))))\n",
    "    retired = lambda x: pd.Categorical(\n",
    "        np.where((x.PENLFRET == 1) | (x.PENLFACT == 5) | \n",
    "                 (x.PEMLR == 5), 1, 0))\n",
    "    school = lambda x: pd.Categorical(\n",
    "        np.where(x.PESCHLVL == 1, 'High School', \n",
    "        np.where((x.PESCHLVL == 2) & (x.PESCHFT == 1), 'Full-time College', \n",
    "        np.where((x.PESCHLVL == 2) & (x.PESCHFT == 2), 'Part-time College', \n",
    "        np.where(x.SCHENR == 0, 'Not Enrolled', None)))))\n",
    "    # Wage variables\n",
    "    wkearn = lambda x: np.where(x.PRERNWA >= 0, x.PRERNWA / 100, None)\n",
    "    hrwage = lambda x: (\n",
    "        np.where((x.PRERNHLY < 0) & (x.PEHRUSL1 > 0 ) & \n",
    "                 (x.PRERNWA > 0), (x.PRERNWA / x.PEHRUSL1) / 100,\n",
    "        np.where(x.PRERNHLY >= 0, x.PRERNHLY / 100, None)))\n",
    "    otcamt = lambda x: np.where(x.PEERN > 0, x.PEERN / 100, None)\n",
    "    priceadj = lambda x: 1 * x.REGION.map(cpi_vals).astype('float')\n",
    "    \n",
    "    # Minimum wage\n",
    "    for start, end, wage in min_wage:\n",
    "        if (date >= start) and (date < end):\n",
    "            fed_min_wage = wage\n",
    "    minwage = lambda x: pd.Categorical( \n",
    "        np.where((x['HRWAGE'] > 0) & (x['HRWAGE'] <= fed_min_wage), 1, \n",
    "        np.where(x['HRWAGE'] > fed_min_wage, 0, None)))\n",
    "    \n",
    "    # Correct weights for implied decimals\n",
    "    df[maps['wgt']] = (df[maps['wgt']] / 10000.0).astype('float32')\n",
    "    \n",
    "    # Assign new variables and drop one ones\n",
    "    df = (df.assign(AGE = age, \n",
    "                    FEMALE = female,\n",
    "                    STATE = state,\n",
    "                    REGION = region,\n",
    "                    EDUCDT = educdt,\n",
    "                    EDUC = educ,\n",
    "                    SCHENR = schenr,\n",
    "                    SCHOOL = school,\n",
    "                    RETIRED = retired,\n",
    "                    MARRIED = married,\n",
    "                    WBHAO = wbhao,\n",
    "                    WBAO = wbao,\n",
    "                    HISPANIC = hispanic,\n",
    "                    VETERAN = veteran,\n",
    "                    FORBORN = forborn,\n",
    "                    CITIZEN = citizen,\n",
    "                    UNEMPTYPE = unemptype,\n",
    "                    JLTYPE = jltype,\n",
    "                    LAYOFF = layoff,\n",
    "                    PTECON = ptecon,\n",
    "                    USLFT = uslft,\n",
    "                    WORKFT = workft,\n",
    "                    FTLF = ftlf,\n",
    "                    SAMEEMP = sameemp,\n",
    "                    CHDUTIES = chduties,\n",
    "                    SAMEACT = sameact,\n",
    "                    CHJOBACT = chjobact,\n",
    "                    NOTATWORK = notatwork,\n",
    "                    ABSTYPE = abstype, \n",
    "                    ABSPAID = abspaid,\n",
    "                    PTREASON = ptreason,\n",
    "                    WANTFT = wantft,\n",
    "                    DWTYPE = dwtype,\n",
    "                    PAIDHRLY = paidhrly,\n",
    "                    PROXY = proxy,\n",
    "                    LFS = lfs,\n",
    "                    COW1 = cow1,\n",
    "                    COW2 = cow2,\n",
    "                    INDGRP = indgrp,\n",
    "                    MANAGER = manager,\n",
    "                    MJH = mjh,\n",
    "                    NUMJOBS = numjobs,\n",
    "                    NILFREASON = nilfreason,\n",
    "                    NLFFAM = nlffam,\n",
    "                    WKEARN = wkearn,\n",
    "                    HRWAGE = hrwage,\n",
    "                    OTCAMT = otcamt,\n",
    "                    PRICEADJ = priceadj,\n",
    "                    MINWAGE = minwage)\n",
    "            .drop(DropVars, axis=1)\n",
    "            .rename({'HRMONTH': 'MONTH', 'HRHHID': 'HHID', \n",
    "                     'PRWERNAL': 'WKEARNFLG',\n",
    "                     'PEPARENT': 'PARENT', 'PRFAMNUM': 'FAMNUM',\n",
    "                     'PRUNEDUR': 'UNEMPDUR', 'PESPOUSE': 'SPOUSE',\n",
    "                     'HRMIS': 'MIS', 'GTCBSA': 'CBSA', 'GTCSA': 'CSA',\n",
    "                     'PEHRACTT': 'HRSACTT', 'PEHRUSLT': 'HRSUSLT',\n",
    "                     'PEHRUSL1': 'HRSUSL1', 'PEHRUSL2': 'HRSUSL2',\n",
    "                     'PEHRACT1': 'HRSACT1', 'PEHRACT2': 'HRSACT2',\n",
    "                     'HWHHWGT': 'HHWGT', 'HEFAMINC': 'FAMINC',\n",
    "                     'PULINENO': 'LINENO'}, axis=1))\n",
    "    \n",
    "    # Wage variables to float32\n",
    "    wage_vars = ['WKEARN', 'OTCAMT', 'HRWAGE']\n",
    "    df[wage_vars] = df[wage_vars].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.494469Z",
     "start_time": "2024-07-25T11:34:44.487740Z"
    },
    "code_folding": [
     3
    ],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.484062Z",
     "iopub.status.busy": "2025-01-17T13:22:46.483812Z",
     "iopub.status.idle": "2025-01-17T13:22:46.488410Z",
     "shell.execute_reply": "2025-01-17T13:22:46.487899Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.484025Z"
    }
   },
   "outputs": [],
   "source": [
    "square = lambda x: x**2\n",
    "cube = lambda x: x**3\n",
    "\n",
    "def impute_hours(df):\n",
    "    spec = '''HRSUSL1 ~ AGE + square(AGE) + cube(AGE) + C(WBHAO) + \n",
    "              C(EDUCDT) + MARRIED + CITIZEN + FORBORN + PRIVATE + \n",
    "              C(STATE) + NUMJOBS + C(INDM) + MANAGER + SELFEMP'''\n",
    "    for s in [0, 1]:\n",
    "        female = (df.FEMALE == s)\n",
    "        for i in ['Full-time', 'Part-time']:\n",
    "            ftpt = (df.FTLF == i)\n",
    "            d = df.loc[ftpt & female]\n",
    "            data = d.query('HRSUSL1 > 0')\n",
    "            fn = smf.ols(formula=spec, data=data)\n",
    "            #print(fn)\n",
    "            reg = fn.fit()\n",
    "            predicted = reg.predict(d)\n",
    "            predicted.values[predicted < 1] = 1\n",
    "            if i == 'Full-time':\n",
    "                predicted.values[predicted < 35] = 35\n",
    "            df.loc[ftpt & female, 'HRSUSL1I'] = predicted\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.503737Z",
     "start_time": "2024-07-25T11:34:44.495803Z"
    },
    "code_folding": [
     0,
     10
    ],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.489285Z",
     "iopub.status.busy": "2025-01-17T13:22:46.489093Z",
     "iopub.status.idle": "2025-01-17T13:22:46.500289Z",
     "shell.execute_reply": "2025-01-17T13:22:46.499720Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.489268Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_above_topcode(group, topcode):\n",
    "    '''CEPR mean above topcode approach for specific columns'''\n",
    "    wage_obs = group.query('WKEARN > 0')\n",
    "    wages = wage_obs.WKEARN.values\n",
    "    wgts = wage_obs.PWORWGT.values\n",
    "    tc_share = (wage_obs.loc[wage_obs.PTWK == 1, 'PWORWGT'].sum() / \n",
    "                wage_obs.PWORWGT.sum())\n",
    "    return mtc_cepr(wages, wgts, topcode, tc_share)\n",
    "\n",
    "\n",
    "def mtc_cepr(data, weights, topcode, topcode_share):\n",
    "    '''\n",
    "    Estimate mean above topcode for lognormally distributed data\n",
    "    '''\n",
    "    if topcode_share == 0:\n",
    "        return np.nan\n",
    "    a = np.log(topcode)\n",
    "    phi = 1 - topcode_share\n",
    "    y = np.log(data)\n",
    "    X = np.average(y, weights=weights)\n",
    "    alpha = norm.ppf(phi) \n",
    "    lmbda = -norm.pdf(alpha) / phi\n",
    "    sigma = (a - X) / (phi * (alpha - lmbda))\n",
    "    mu = a - (alpha * sigma)\n",
    "    hlambda = norm.pdf(alpha) / (1 - norm.cdf(alpha))\n",
    "    mtc = mu + sigma * hlambda\n",
    "    return np.exp(mtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.530887Z",
     "start_time": "2024-07-25T11:34:44.505172Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.501311Z",
     "iopub.status.busy": "2025-01-17T13:22:46.501122Z",
     "iopub.status.idle": "2025-01-17T13:22:46.518314Z",
     "shell.execute_reply": "2025-01-17T13:22:46.517776Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.501294Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_special(dfm, maps, cpi_vals, date):\n",
    "    \n",
    "    # New variables in selected dates:\n",
    "    wbhaom = lambda x: pd.Categorical(\n",
    "        np.where(x['PRDTHSP'].isin(maps['hisp']), 'Hispanic', \n",
    "                 x['PRDTRACE'].map(maps['racem'])))\n",
    "    hispdt = lambda x: pd.Categorical(x['PRDTHSP'].map(maps['hispdt']))\n",
    "    hispdt03 = lambda x: pd.Categorical(x['PRDTHSP'].map(maps['hispdt03']))\n",
    "    cert = lambda x: pd.Categorical(\n",
    "        np.where(x['PECERT1'] == 1, 1, np.where(x['PECERT1']==2, 0, np.nan)))\n",
    "    ctybirth94 = lambda x: pd.Categorical(x['PENATVTY'].map(COB1994Map))\n",
    "    ctybirth07 = lambda x: pd.Categorical(x['PENATVTY'].map(COB2007Map))\n",
    "    county = lambda x: pd.Categorical(\n",
    "        np.where(x['GTCO'] > 0, x['GTCO'] * 100 + x['GESTFIPS'], 0))\n",
    "    mpcstat = lambda x: pd.Categorical(\n",
    "        np.where(x.MSAST == 1, 'Principal City',\n",
    "        np.where(x.MSAST == 2, 'Balance',\n",
    "        np.where(x.MSAST == 3, 'Nonmetropolitan',\n",
    "        np.where(x.MSAST == 4, 'Not Identified', None)))))\n",
    "    metstat = lambda x: pd.Categorical(\n",
    "        np.where(x.METSTA == 1, 'Metropolitan',\n",
    "        np.where(x.METSTA == 2, 'Nonmetropolitan',\n",
    "        np.where(x.METSTA == 3, 'Not Identified', None))))\n",
    "    \n",
    "    # Revised weights for December 2007\n",
    "    if date == pd.to_datetime('2007-12-01'):\n",
    "        df_rev = pd.read_feather('clean/cps_dec07_rev.ft')\n",
    "        dfm = pd.merge(dfm, df_rev)\n",
    "        dfm['PWSSWGT'] = dfm['NWSSWGT']\n",
    "        dfm['PWCMPWGT'] = dfm['NWCMPWGT']\n",
    "        dfm = dfm.drop(['NWSSWGT', 'NWCMPWGT'], axis=1)\n",
    "\n",
    "    # Country of origin revised in 2007    \n",
    "    if date.year < 2007:\n",
    "        dfm = dfm.assign(CTYBIRTH = ctybirth94)\n",
    "    if date.year >= 2007:\n",
    "        dfm = dfm.assign(CTYBIRTH = ctybirth07) \n",
    "    dfm = dfm.drop(['PENATVTY'], axis=1)   \n",
    "    dfm['CTYBIRTH'] = dfm['CTYBIRTH'].astype('category')\n",
    "\n",
    "    # Four digit year\n",
    "    if date.year < 1998:\n",
    "        dfm['HRYEAR4'] = dfm['HRYEAR'] + 1900\n",
    "        dfm = dfm.drop(['HRYEAR'], axis=1)\n",
    "        \n",
    "        # Person weight is basic weight\n",
    "        dfm['BASICWGT'] = dfm['PWSSWGT'] \n",
    "        \n",
    "    dfm = dfm.rename({'HRYEAR4': 'YEAR'}, axis=1)\n",
    "\n",
    "    # Person weight is composite weight\n",
    "    if date.year >= 1998:\n",
    "        dfm = dfm.rename({'PWCMPWGT': 'BASICWGT'}, axis=1)\n",
    "\n",
    "    # Detailed race allows identifying more than one race\n",
    "    if date.year > 2002:\n",
    "        dfm = dfm.assign(WBHAOM = wbhaom)\n",
    "        dfm = dfm.assign(HISPDT03 = hispdt03)\n",
    "    if date.year > 2013:\n",
    "        dfm = dfm.assign(HISPDT = hispdt)        \n",
    "    dfm = dfm.drop(['PRDTHSP'], axis=1)\n",
    "    \n",
    "    # Atlanta Fed Wage Growth Tracker Flag\n",
    "    # atlflg = lambda x: np.where((x.PTHR == 0) & (x.PTWK == 0) & (x.PRNAGWS == 1)\n",
    "    #                            & (x.PRHERNAL < 1) & (x.WKEARNFLG < 1), 1, 0)\n",
    "    # drop_vars = ['PTHR', 'PRHERNAL', 'PRNAGWS']\n",
    "    # drop_vars = [dv for dv in drop_vars if dv in dfm.keys()]\n",
    "    # if date >= pd.to_datetime('1995-09-01'):\n",
    "    #     dfm = dfm.assign(ATLFLG = atlflg)\n",
    "    # dfm = dfm.drop(drop_vars, axis=1) \n",
    "    \n",
    "    # Renaming major industry and occupation codes\n",
    "    if date.year >= 2003:\n",
    "        dfm = dfm.rename({'PRMJOCC1': 'OCC03M', 'PRMJOCC2': 'OCC203M', \n",
    "                          'PRDTOCC1': 'OCC03D', 'PRDTOCC2': 'OCC203D',\n",
    "                          'PRMJIND1': 'IND03M', 'PRMJIND2': 'IND203M', \n",
    "                          'PRDTIND1': 'IND03D', 'PRDTIND2': 'IND203D'}, axis=1)\n",
    "    if date.year < 2003:\n",
    "        dfm = dfm.rename({'PRMJOCC1': 'OCC80M', 'PRMJOCC2': 'OCC280M', \n",
    "                          'PRDTOCC1': 'OCC80D', 'PRDTOCC2': 'OCC280D',\n",
    "                          'PRMJIND1': 'IND80M', 'PRMJIND2': 'IND280M', \n",
    "                          'PRDTIND1': 'IND80D', 'PRDTIND2': 'IND280D',\n",
    "                          'PEIO1OCD': 'OCC90', 'PEIO2OCD': 'OCC290', \n",
    "                          'PEIO1ICD': 'IND90', 'PEIO2ICD': 'IND290'}, axis=1)\n",
    "      \n",
    "    # Renaming industry and occupation codes\n",
    "    if 2003 <= date.year <= 2008:\n",
    "        dfm = dfm.rename({'PEIO1ICD': 'IND02', 'PEIO2ICD': 'IND202'}, axis=1)\n",
    "    if 2003 <= date.year <= 2010:\n",
    "        dfm = dfm.rename({'PEIO1OCD': 'OCC00', 'PEIO2OCD': 'OCC200'}, axis=1)    \n",
    "    if 2009 <= date.year <= 2013:\n",
    "        dfm = dfm.rename({'PEIO1ICD': 'IND07', 'PEIO2ICD': 'IND207'}, axis=1) \n",
    "    if 2011 <= date.year <= 2019:\n",
    "        dfm = dfm.rename({'PEIO1OCD': 'OCC10', 'PEIO2OCD': 'OCC210'}, axis=1)    \n",
    "    if 2014 <= date.year <= 2019:\n",
    "        dfm = dfm.rename({'PEIO1ICD': 'IND12', 'PEIO2ICD': 'IND212'}, axis=1)         \n",
    "    if date.year >= 2020:\n",
    "        dfm = dfm.rename({'PEIO1OCD': 'OCC18', 'PEIO2OCD': 'OCC218',\n",
    "                          'PEIO1ICD': 'IND17', 'PEIO2ICD': 'IND217'}, axis=1)  \n",
    "        \n",
    "    # Major industry recode consistent over years\n",
    "    for indvar in ['IND90', 'IND02', 'IND07', 'IND12', 'IND17']:\n",
    "        if indvar in dfm.keys():\n",
    "            indmap = {i: k for k, v in INDMMap.items() for i in v[indvar]}\n",
    "            indm = lambda x: pd.Categorical(x[indvar].map(indmap))\n",
    "            dfm = dfm.assign(INDM = indm)\n",
    "        \n",
    "    # Detailed Asian Race\n",
    "    asiandt = lambda x: pd.Categorical(x['PRDASIAN'].map(AsianMap))\n",
    "    if date.year >= 2013:\n",
    "        dfm = dfm.assign(ASIANDT = asiandt).drop(['PRDASIAN'], axis=1) \n",
    "\n",
    "    # Professional certification questions\n",
    "    if date.year in [2015, 2016]:\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        rev_df = (pd.read_feather(f'clean/cps_cert{year}.ft')\n",
    "                    .query('MONTH == @month'))\n",
    "        dfm = pd.merge(dfm, rev_df, how='outer')\n",
    "\n",
    "    if date.year >= 2015:\n",
    "        dfm = dfm.assign(CERT = cert).drop(['PECERT1'], axis=1)\n",
    "        \n",
    "    # Disability status\n",
    "    if (date >= pd.to_datetime('2008-06-01') ) and (date.year < 2009):\n",
    "        month = date.month\n",
    "        feather_file = 'clean/cps_disability2008.ft'\n",
    "        rev_df = (pd.read_feather(feather_file)\n",
    "                    .query('MONTH == @month')\n",
    "                    .drop(['MONTH'], axis=1))\n",
    "        dfm = pd.merge(dfm, rev_df, on=['QSTNUM', 'OCCURNUM'], how='outer')\n",
    "    if date >= pd.to_datetime('2008-06-01'):\n",
    "        disability = lambda x: pd.Categorical(\n",
    "            np.where(x['PRDISFLG'] == 1, 1, 0))\n",
    "        dfm = dfm.assign(DISABILITY = disability).drop(['PRDISFLG'], axis=1)\n",
    "   \n",
    "    # Matching HRHHID2 in cases where it must be created manually\n",
    "    if maps['id2'] == True:\n",
    "        dfm['HRHHID2'] = id2_gen(dfm)\n",
    "        dfm = dfm.drop(['HRSAMPLE', 'HRSERSUF', 'HUHHNUM'], axis=1)\n",
    "        \n",
    "    dfm = dfm.rename({'HRHHID2': 'HHID2'}, axis=1)\n",
    "    \n",
    "    # Add QSTNUM and OCCURNUM where not available\n",
    "    if date.year < 1998:\n",
    "        dfm['QSTNUM'] = dfm.groupby(['HHID','HHID2']).ngroup().astype('int32')\n",
    "        dfm['OCCURNUM'] = (dfm.groupby('QSTNUM').cumcount() + 1).astype('int8')\n",
    "    \n",
    "    # Unique household IDS\n",
    "    if date > pd.to_datetime('1995-05-01'): \n",
    "        ids_file = 'CPS_unique_ids.pkl'\n",
    "        if os.path.isfile(ids_file):\n",
    "            dfm['CPSID'] = dfm['QSTNUM'].map(cps_ids_full[date])\n",
    "    if date <= pd.to_datetime('1995-05-01'): \n",
    "        ids_file = 'CPSID_89-93.pkl'\n",
    "        if os.path.isfile(ids_file):\n",
    "            dfm['CPSID'] = dfm['QSTNUM'].map(cps_ids_full_early[date])\n",
    "      \n",
    "    # Merge in COVID data\n",
    "    #if date >= pd.to_datetime('2020-05-01'):\n",
    "    #    rev_df = (pd.read_feather(f'clean/cps_covid_{date.year}.ft')\n",
    "    #                .query('MONTH == @date.month'))\n",
    "    #    dfm = pd.merge(dfm, rev_df)         \n",
    "        \n",
    "    # Parent 2020 onward\n",
    "    parent = lambda x: np.where(x.PEPAR2 > 0, x.PEPAR2, \n",
    "                       np.where(x.PEPAR1 > 0, x.PEPAR1, -1))\n",
    "    if date >= pd.to_datetime('2020-01-01'):\n",
    "        dfm = (dfm.assign(PARENT = parent)\n",
    "                  .astype({'PARENT': 'int8'})\n",
    "                  .drop(['PEPAR1', 'PEPAR2'], axis=1))\n",
    "    \n",
    "    # County code (state and county combined)\n",
    "    if date >= pd.to_datetime('1995-09-01'): \n",
    "        dfm = dfm.assign(COUNTY = county)\n",
    "        dfm = dfm.drop(['GESTFIPS', 'GTCO'], axis=1)\n",
    "    elif date >= pd.to_datetime('1995-01-01'):\n",
    "        dfm['COUNTY'] = -1\n",
    "        dfm = dfm.drop(['GESTFIPS'], axis=1)\n",
    "    else:\n",
    "        dfm = dfm.drop(['GESTFIPS'], axis=1)\n",
    "        \n",
    "    # Metropolitan/Principal City Status\n",
    "    if ((date >= pd.to_datetime('1995-06-01')) & \n",
    "        (date <= pd.to_datetime('1995-08-01'))):\n",
    "        dfm['MSAST'] = 4\n",
    "        dfm['METSTA'] = 3\n",
    "        dfm['CMSA'] = -1\n",
    "        dfm['MSA'] = -1\n",
    "    if ((date >= pd.to_datetime('2004-05-01')) & \n",
    "        (date <= pd.to_datetime('2004-12-01'))):\n",
    "        dfm['CMSA'] = -1\n",
    "        dfm['MSA'] = -1\n",
    "    if ((date >= pd.to_datetime('2004-01-01')) & \n",
    "        (date <= pd.to_datetime('2004-04-01'))):\n",
    "        dfm['CBSA'] = -1\n",
    "        dfm['CSA'] = -1\n",
    "    dfm = (dfm.assign(METSTAT = metstat, MPCSTAT = mpcstat)\n",
    "              .drop(['MSAST', 'METSTA'], axis=1))\n",
    "    \n",
    "    # Imputed mean above topcode weekly\n",
    "    # if date.year < 1998: \n",
    "    #     topcode = 1923.0\n",
    "    # elif date.year >= 1998:\n",
    "    #     topcode = 2884.61\n",
    "    # rsd = (dfm.groupby(['REGION', 'FEMALE'], group_keys=True)\n",
    "    #           .apply(lambda x: mean_above_topcode(x, topcode))\n",
    "    #           .to_dict())\n",
    "    # dfm['WKEARNADJ'] = pd.Series(dtype='float32')\n",
    "    # for group, value in rsd.items():\n",
    "    #     mask = (dfm.PTWK == 1) & (dfm.REGION == group[0]) & (dfm.FEMALE == group[1])\n",
    "    #     dfm.loc[mask, 'WKEARNADJ'] = value\n",
    "    \n",
    "    # Imputed usual hours worked on first job\n",
    "    # private = lambda x: np.where(x['COW1'] == 'Private', 1, 0)\n",
    "    # se = ['Self-employed Incorporated', 'Self-employed Unincorporated']\n",
    "    # selfemp = lambda x: np.where(x.COW1.isin(se), 1, 0)\n",
    "    # dfm = (impute_hours(dfm.assign(PRIVATE = private, SELFEMP = selfemp))\n",
    "    #        .drop(['PRIVATE', 'SELFEMP'], axis=1)\n",
    "    #        .astype({'HRSUSL1I': 'float16'}))\n",
    "    \n",
    "    # hrwageadj = (\n",
    "    # lambda x: np.where((x.PRERNHLY >= 0) & (x.PEERN < 1), \n",
    "    #                    x.PRERNHLY / 100.0,\n",
    "    #           np.where((x.WKEARNADJ >= 0) & (x.HRSUSL1 > 0), \n",
    "    #                    (x.WKEARNADJ / x.HRSUSL1),\n",
    "    #           np.where((x.WKEARNADJ >= 0) & (x.HRSUSL1 == -4), \n",
    "    #                    (x.WKEARNADJ / x.HRSUSL1I), np.nan)))) \n",
    "\n",
    "    # drop_list = ['PRERNHLY', 'PEERN', 'PRERNWA']\n",
    "    # dfm = (dfm.assign(HRWAGEADJ = hrwageadj)\n",
    "    #           .astype({'HRWAGEADJ': 'float32',\n",
    "    #                    'WKEARNADJ': 'float32'})\n",
    "    #           .drop(drop_list, axis=1))\n",
    "    \n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.544597Z",
     "start_time": "2024-07-25T11:34:44.532189Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.519445Z",
     "iopub.status.busy": "2025-01-17T13:22:46.519247Z",
     "iopub.status.idle": "2025-01-17T13:22:46.527908Z",
     "shell.execute_reply": "2025-01-17T13:22:46.527317Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.519428Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def revised_annual_data(df, year):\n",
    "    \n",
    "    # Merge in the 2000-revised weights and io recodes here\n",
    "    if 2000 <= year <= 2002:\n",
    "        rev_wgts = pd.read_feather(f'clean/cps_wgt_rev{year}.ft')\n",
    "        df = pd.merge(df, rev_wgts)\n",
    "        df['BASICWGT'] = df['NWCMPWGT']\n",
    "        df['PWORWGT'] = df['NWORWGT']\n",
    "        df['PWSSWGT'] = df['NWSSWGT']\n",
    "        df['HHWGT'] = df['NWHHWGT']\n",
    "        df = df.drop(['NWCMPWGT', 'NWORWGT', 'NWSSWGT', 'NWHHWGT'], axis=1)\n",
    "        # IO recodes\n",
    "        rev_io = pd.read_feather(f'clean/cps_io_rev{year}.ft')\n",
    "        df = pd.merge(df, rev_io)       \n",
    "        \n",
    "    # Merge in revised union data\n",
    "    if year in [2001, 2002]:\n",
    "        rev_df = pd.read_feather(f'clean/cps_union_rev{year}.ft')\n",
    "        df = pd.merge(df, rev_df)\n",
    "        df['PEERNLAB'] = df['NEERNLAB']\n",
    "        df['PEERNCOV'] = df['NEERNCOV']\n",
    "        df = df.drop(['NEERNLAB', 'NEERNCOV'], axis=1)\n",
    "        \n",
    "    # Create UNION and UNIONMEM\n",
    "    union = lambda x: pd.Categorical(\n",
    "        np.where((x['PEERNLAB'] == 1) | (x['PEERNCOV'] == 1), 1, \n",
    "        np.where((x['PEERNLAB'] == 2) & (x['PEERNCOV'] == 2), 0, None)), \n",
    "        ordered=True)\n",
    "    unionmem = lambda x: pd.Categorical(\n",
    "        np.where(x['PEERNLAB'] == 1, 1, \n",
    "        np.where(x['PEERNLAB'] == 2, 0, None)), \n",
    "        ordered=True)\n",
    "    \n",
    "    df = (df.assign(UNION = union, UNIONMEM = unionmem)\n",
    "            .drop(['PEERNLAB', 'PEERNCOV'], axis=1))\n",
    "    \n",
    "    # General mess clean up area\n",
    "    cat_vars = ['PRDTRACE', 'COW2', 'REGION', 'CSA', 'CBSA', 'CTYBIRTH', 'YEAR',\n",
    "                'DISABILITY', 'INDGRP', 'IND80D', 'OCC80D',\n",
    "                'IND80M', 'OCC80M', 'IND03D', 'OCC03D', 'OCC03M', \n",
    "                'IND03M', 'IND203M', 'IND203D', 'OCC203D', 'OCC203M',\n",
    "                'OCC280M', 'IND280M', 'OCC280D', 'IND280D', \n",
    "                'OCC90', 'OCC290', 'OCC00', 'OCC200', 'OCC10', 'OCC210', 'OCC18',\n",
    "                'OCC218', 'IND90', 'IND290', 'IND02', 'IND202', 'IND07', 'IND207',\n",
    "                'IND12', 'IND212', 'IND17', 'IND217',\n",
    "                'HRSUSL1',\n",
    "                'CMSA', 'MSA', 'COUNTY', 'PTCOVID1', 'PTCOVID2', 'PTCOVID3',\n",
    "                'PTCOVID4', 'HHID2', 'FAMNUM', 'METSTAT', 'MPCSTAT', 'USLFT',\n",
    "                'ABSTYPE', 'FTLF', 'FAMINC', 'PTREASON', 'WANTFT', #'ATLFLG', \n",
    "                'WKEARNFLG', 'PTWK', 'GTCBSASZ', 'SAMEEMP', 'CHDUTIES', 'SAMEACT',\n",
    "                'CHJOBACT']\n",
    "    cat_vars = [cv for cv in cat_vars if cv in df.keys()]\n",
    "    convert_dict = {cat: 'category' for cat in cat_vars}\n",
    "    df = df.astype(convert_dict)\n",
    "    # Clean up int vars\n",
    "    intvars = ['SPOUSE', 'PARENT']\n",
    "    df[intvars] = df[intvars].fillna(-1).astype('int8')\n",
    "    # Fix prnmchld size 1999\n",
    "    chvars = ['PRCHLD', 'PRNMCHLD']\n",
    "    if year == 1999:\n",
    "        df[chvars] = df[chvars].fillna(-1).astype('int8')\n",
    "    wgt_vars = ['BASICWGT', 'PWSSWGT', 'PWORWGT', 'HHWGT']\n",
    "    df[wgt_vars] = df[wgt_vars].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:44.553153Z",
     "start_time": "2024-07-25T11:34:44.546810Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.528766Z",
     "iopub.status.busy": "2025-01-17T13:22:46.528583Z",
     "iopub.status.idle": "2025-01-17T13:22:46.536758Z",
     "shell.execute_reply": "2025-01-17T13:22:46.536149Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.528748Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def cps_to_feather(year_list):\n",
    "    data_dictionary = None \n",
    "    for year in year_list:\n",
    "        \n",
    "        # Get the list of raw data files for the given year\n",
    "        file_ending = f'{str(year)[2:]}pub.dat'\n",
    "        raw_files = [file for file in data_files \n",
    "                     if file.endswith(file_ending)]\n",
    "        \n",
    "        # Loop over individual raw monthly files\n",
    "        combined_data = []\n",
    "        for file in raw_files:\n",
    "            # Date of raw monthly file\n",
    "            date = pd.to_datetime(f'{year}-{file[:3]}-01')\n",
    "            # Month's CPI values (by region)\n",
    "            cpi_vals = cpi.loc[date].to_dict()\n",
    "            \n",
    "            # Identify how to read the raw data file\n",
    "            if data_dictionary != cpsdd['matcher'][file]:\n",
    "                data_dictionary = cpsdd['matcher'][file]\n",
    "                dd_info = cpsdd[data_dictionary]\n",
    "                var_info = dd_info['dd']\n",
    "                ws, we = var_info['PWSSWGT'][:2]\n",
    "                dtypes = [(var_name, var_details[-1]) \n",
    "                          for var_name, var_details in var_info.items()]\n",
    "                var_maps = dd_info['map']\n",
    "                unpack_format = dd_info['unpack_fmt']\n",
    "                unpacker = struct.Struct(unpack_format).unpack_from\n",
    "                \n",
    "            # Read raw monthly data and return pandas dataframe\n",
    "            mo_data = data_file_reader(file, unpacker, dtypes, ws, we)\n",
    "            \n",
    "            # Clean up the data\n",
    "            dfm = clean_all(mo_data, var_maps, cpi_vals, date)\n",
    "            clean_mo_data = clean_special(dfm, var_maps, cpi_vals, date)\n",
    "            \n",
    "            combined_data.append(clean_mo_data)\n",
    "            \n",
    "        # Combine monthly files into one annual file\n",
    "        df = (pd.concat(combined_data, sort=False)\n",
    "                .reset_index(drop=True))\n",
    "        \n",
    "        # Census revised 2000-based weights and union data\n",
    "        df = revised_annual_data(df, year)\n",
    "        \n",
    "        df.to_feather(f'clean/cps{year}.ft')\n",
    "        obs = len(df)\n",
    "        cols = len(df.keys())\n",
    "        size = round(df.memory_usage().sum() / 1024**2, 1)\n",
    "        print(f'{year} Done: ({obs:,} records, {cols} variables, {size}MB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:34:56.651370Z",
     "start_time": "2024-07-25T11:34:44.554461Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-17T13:22:46.537787Z",
     "iopub.status.busy": "2025-01-17T13:22:46.537428Z",
     "iopub.status.idle": "2025-01-17T13:38:39.407553Z",
     "shell.execute_reply": "2025-01-17T13:38:39.407044Z",
     "shell.execute_reply.started": "2025-01-17T13:22:46.537768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118652/3802528218.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = (pd.concat(combined_data, sort=False)\n",
      "/tmp/ipykernel_118652/3802528218.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = (pd.concat(combined_data, sort=False)\n",
      "/tmp/ipykernel_118652/3802528218.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = (pd.concat(combined_data, sort=False)\n",
      "/tmp/ipykernel_118652/3802528218.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = (pd.concat(combined_data, sort=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994 Done: (1,672,934 records, 108 variables, 300.0MB)\n",
      "1995 Done: (1,648,060 records, 111 variables, 312.8MB)\n",
      "1996 Done: (1,461,469 records, 111 variables, 267.7MB)\n",
      "1997 Done: (1,462,817 records, 111 variables, 267.9MB)\n",
      "1998 Done: (1,461,394 records, 111 variables, 267.7MB)\n",
      "1999 Done: (1,465,602 records, 113 variables, 271.2MB)\n",
      "2000 Done: (1,460,714 records, 125 variables, 292.6MB)\n",
      "2001 Done: (1,560,956 records, 125 variables, 312.7MB)\n",
      "2002 Done: (1,703,004 records, 125 variables, 341.2MB)\n",
      "2003 Done: (1,685,264 records, 115 variables, 315.1MB)\n",
      "2004 Done: (1,656,144 records, 118 variables, 316.0MB)\n",
      "2005 Done: (1,644,787 records, 116 variables, 310.7MB)\n",
      "2006 Done: (1,628,798 records, 116 variables, 306.1MB)\n",
      "2007 Done: (1,611,901 records, 116 variables, 304.4MB)\n",
      "2008 Done: (1,600,790 records, 117 variables, 303.9MB)\n",
      "2009 Done: (1,617,099 records, 117 variables, 307.0MB)\n",
      "2010 Done: (1,621,021 records, 117 variables, 307.7MB)\n",
      "2011 Done: (1,600,068 records, 117 variables, 303.7MB)\n",
      "2012 Done: (1,588,264 records, 117 variables, 301.5MB)\n",
      "2013 Done: (1,576,085 records, 118 variables, 300.7MB)\n",
      "2014 Done: (1,582,739 records, 119 variables, 303.5MB)\n",
      "2015 Done: (1,561,469 records, 120 variables, 300.9MB)\n",
      "2016 Done: (1,553,528 records, 120 variables, 299.3MB)\n",
      "2017 Done: (1,524,812 records, 120 variables, 293.8MB)\n",
      "2018 Done: (1,474,979 records, 120 variables, 284.2MB)\n",
      "2019 Done: (1,419,262 records, 120 variables, 273.5MB)\n",
      "2020 Done: (1,269,179 records, 120 variables, 244.6MB)\n",
      "2021 Done: (1,275,670 records, 120 variables, 245.8MB)\n",
      "2022 Done: (1,218,890 records, 120 variables, 234.9MB)\n",
      "2023 Done: (1,191,295 records, 120 variables, 229.6MB)\n",
      "2024 Done: (1,183,538 records, 120 variables, 236.0MB)\n"
     ]
    }
   ],
   "source": [
    "cps_to_feather(range(1994, 2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:02:50.989959Z",
     "start_time": "2024-06-12T22:02:50.979424Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
