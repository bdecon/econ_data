{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_1989-93.ipynb\n",
    "\n",
    "April 16, 2019\n",
    "\n",
    "Contact: Brian Dew, @bd_econ\n",
    "\n",
    "----\n",
    "\n",
    "### About\n",
    "\n",
    "**Goal:** Use python to work with Current Population Survey data from 1989-93.\n",
    "\n",
    "This notebook reads raw CPS data from Census, downloaded from [NBER](https://www.nber.org/data/cps_basic.html), to generate annual feather-format files that match with the bd CPS extracts for 1994-onward. A major revision to the CPS in 1994 makes it impossible to completely match the 1989-93 data to the 1994-onward data, but this notebook attempts to adjust the 1989-93 data to match with 1994-onward data as close as possible. \n",
    "\n",
    "See the [GitHub repo page](https://github.com/bdecon/econ_data/tree/master/bd_CPS) for details on how to use the bd CPS and on what variables are available and how they are defined. See also the [benchmark notebook](https://github.com/bdecon/econ_data/blob/master/micro/bd_CPS_benchmark.ipynb) for examples of using the 1989-93 data. \n",
    "\n",
    "-----\n",
    "\n",
    "See [issues](https://github.com/bdecon/econ_data/issues?q=is%3Aopen+is%3Aissue+label%3A1989-93) and [project](https://github.com/bdecon/econ_data/projects/4) on Github. Please feel free to contact me if you have any questions or are interested in helping with the project. My email address is brianwdew@gmail.com.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "See this [discussion of the CPS revamp](https://www.bls.gov/cps/revisions1994.pdf) for guidance on matching the 1989-93 data to the 1994-onward data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:12:14.562291Z",
     "start_time": "2024-06-12T23:12:13.818474Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.3.3\n",
      "numpy: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# import libraries and settings\n",
    "import os, re, struct, pickle, shutil\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "import numpy as np\n",
    "print('numpy:', np.__version__)\n",
    "\n",
    "# Map codes for country of birth to country/area names\n",
    "from bd_CPS_details import EducDTMap, INDMMap, INDGRPMap\n",
    "\n",
    "data_dir = '/home/brian/Documents/CPS/data/'\n",
    "\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Data dictionary file generated by bd_CPS_dd.ipynb\n",
    "cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))\n",
    "\n",
    "# Dictionary of unique IDS\n",
    "ids_file = 'CPSID_89-93.pkl'\n",
    "if os.path.isfile(ids_file):\n",
    "    cps_ids_full = pickle.load(open(ids_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:12:14.569231Z",
     "start_time": "2024-06-12T23:12:14.563902Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# If running for first time, unzip the annual NBER zip files in raw data \n",
    "# folder and run this block of code. It will rename the files accordingly.\n",
    "\n",
    "# Check if files exist:\n",
    "date_range = [dt.strftime('%b%y').lower() for dt in \n",
    "              pd.date_range(start='1989-01-01', end='1993-12-01', freq='MS')]\n",
    "correct_files = [f'{date}pub.dat' for date in date_range]\n",
    "if correct_files not in os.listdir():\n",
    "    # Rename unzipped NBER files\n",
    "    raw_files = [f for f in os.listdir() if f.startswith('cpsb') \n",
    "                 and '.dat' not in f and '.zip' not in f]\n",
    "    to_rename = list(set(raw_files) - set(correct_files))\n",
    "    for file in to_rename:\n",
    "        date = pd.to_datetime(f'19{file[4:6]}-{file[6:8]}-01')\n",
    "        os.rename(file, date.strftime('%b%y').lower() + 'pub.dat')\n",
    "        print('Renamed: ', file, date.strftime('%b%y').lower() + 'pub.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:12:14.591752Z",
     "start_time": "2024-06-12T23:12:14.570518Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_43535/2994776803.py:14: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  p = ('(\\\\w{1,2}[\\\\$\\-%]\\\\w*|PADDING)\\\\s'\n",
      "/tmp/ipykernel_43535/2994776803.py:15: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  '*CHARACTER\\\\*(\\\\d{3})\\\\s*\\.{0,1}\\\\s*\\((\\\\d*):(\\\\d*)\\).*')\n"
     ]
    }
   ],
   "source": [
    "# User-defined functions\n",
    "def id_dtype(size):\n",
    "    '''Return data type based on fixed-width size'''\n",
    "    size = int(size)\n",
    "    dtype = ('intp' if size > 9 \n",
    "             else 'int32' if size > 4 \n",
    "             else 'int16' if size > 2 \n",
    "             else 'int8')\n",
    "    return dtype\n",
    "\n",
    "def data_dict_reader(dd_file, var_list):\n",
    "    '''Read data dictionary and return variable locations'''\n",
    "    data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "    p = ('(\\\\w{1,2}[\\\\$\\-%]\\\\w*|PADDING)\\\\s'\n",
    "         '*CHARACTER\\\\*(\\\\d{3})\\\\s*\\.{0,1}\\\\s*\\((\\\\d*):(\\\\d*)\\).*')\n",
    "    d = {s[0]: [int(s[2])-1, int(s[3]), f'{int(s[1])}s', id_dtype(s[1])]\n",
    "         for s in re.findall(p, data_dict) if s[0] in var_list}\n",
    "    return d\n",
    "\n",
    "def struct_unpacker(d):\n",
    "    '''Return struct unpacker from variable locations'''\n",
    "    start, end, width, size = zip(*d.values())\n",
    "    skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "    return struct.Struct(unpack_fmt).unpack_from\n",
    "\n",
    "def data_file_reader(file, unpacker, dtypes, wgt):\n",
    "    '''Convert raw monthly file to pandas dataframe'''\n",
    "    raw_data = open(file, 'rb')\n",
    "    data = [unpacker(row) for row in raw_data if len(row) >= 405]\n",
    "    data = [tuple(int(i) if i.strip() else -1 for i in row) for row in data]\n",
    "    np_data = np.array(data, dtype=dtypes)\n",
    "    df = pd.DataFrame(np_data[np_data[wgt] > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:24.136822Z",
     "start_time": "2024-06-12T23:12:14.593531Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989 Done: (1,713,347 records, 59 variables, 176.5MB)\n",
      "1990 Done: (1,791,585 records, 59 variables, 184.6MB)\n",
      "1991 Done: (1,774,232 records, 59 variables, 182.8MB)\n",
      "1992 Done: (1,746,184 records, 59 variables, 179.9MB)\n",
      "1993 Done: (1,722,398 records, 59 variables, 177.4MB)\n"
     ]
    }
   ],
   "source": [
    "# Create annual feather files\n",
    "dd_files = {'cps89.ddf': [1989, 1990, 1991],\n",
    "            'cps92.ddf': [1992, 1993]}\n",
    "\n",
    "var_list = ['H-MONTH', 'H-YEAR', 'H-MIS', 'HG-FIPS', 'H-METSTA', 'HG-MSAS',\n",
    "            'H-ID', 'A-LINENO', 'A-AGE', 'A-MARITL', 'A-SEX', 'A-HGA',\n",
    "            'A-RACE', 'A-IND', 'A-OCC', 'A-CLSWKR', 'HG-MSAC', 'HG-CMSA',\n",
    "            'A-USLHRS', 'A-UNMEM', 'A-REORGN', 'A-LFSR', 'A-ENRLW',\n",
    "            'A-UNTYPE', 'A-FNLWGT', 'A-ERNLWT', 'A-HRLYWK', 'H-HHWGT',\n",
    "            'A-HERNTP', 'A-WERNTP', 'A-HRS1', 'A-WKSLK', 'H-HHNUM',\n",
    "            'A-UNCOV', 'A-HGC', 'A-MJIND', 'A-MJOCC', 'A-WKSTAT', \n",
    "            'A-DTOCC', 'A-DTIND', 'A-SPOUSE', 'A-PARENT', 'A-EMPHRS',\n",
    "            'H-HTYPE', 'A-FTPT', 'A-HSCOL', 'A-VET', 'H-FAMINC',\n",
    "            'A-USLFT', 'A-RRP']\n",
    "\n",
    "# Remove the first two characters from each variable name\n",
    "rename_list = {v: v[2:] for v in var_list if v[0:2] != 'HG'}\n",
    "rename_list['HG-FIPS'] = 'STATEFIPS'\n",
    "rename_list['A-WKSLK'] = 'UNEMPDUR'\n",
    "rename_list['HG-MSAC'] = 'MSA'\n",
    "rename_list['HG-CMSA'] = 'CMSA'\n",
    "rename_list['HG-MSAS'] = 'MSAS'\n",
    "filter_wgt = 'A-FNLWGT'\n",
    "\n",
    "# Map state FIPS codes to two letter codes\n",
    "state_codes = cpsdd['jan94_mar94_dd.txt']['map']['state']\n",
    "region_codes = cpsdd['jan94_mar94_dd.txt']['map']['region']\n",
    "state = lambda x: pd.Categorical(x['STATEFIPS'].map(state_codes))\n",
    "region = lambda x: x['STATE'].map(region_codes)\n",
    "\n",
    "# Metro and Principal city status\n",
    "mpcstat = lambda x: pd.Categorical(\n",
    "    np.where(x.MSAS == 1, 'Principal City',\n",
    "    np.where(x.MSAS == 2, 'Balance',\n",
    "    np.where(x.MSAS == 3, 'Nonmetropolitan',\n",
    "    np.where(x.MSAS == 4, 'Not Identified', None)))))\n",
    "metstat = lambda x: pd.Categorical(\n",
    "    np.where(x.METSTA == 1, 'Metropolitan',\n",
    "    np.where(x.METSTA == 2, 'Nonmetropolitan',\n",
    "    np.where(x.METSTA == 3, 'Not Identified', None))))\n",
    "\n",
    "# 1992-onward educ codes\n",
    "educ_codes = cpsdd['jan94_mar94_dd.txt']['map']['educ']\n",
    "educ = lambda x: x['HGA'].map(educ_codes)\n",
    "educdt = lambda x: pd.Categorical(x['HGA'].map(EducDTMap))\n",
    "\n",
    "# School enrollment\n",
    "schenr = lambda x: pd.Categorical(\n",
    "    np.where(x['ENRLW'] == 1, 1, \n",
    "    np.where(x['ENRLW'] == 2, 0, None)))\n",
    "\n",
    "school = lambda x: pd.Categorical(\n",
    "    np.where(x.HSCOL == 1, 'High School', \n",
    "    np.where((x.HSCOL == 2) & (x.FTPT == 1), 'Full-time College', \n",
    "    np.where((x.HSCOL == 2) & (x.FTPT == 2), 'Part-time College', None))))\n",
    "\n",
    "# major industry group\n",
    "ind_codes = cpsdd['jan94_mar94_dd.txt']['map']['ind']\n",
    "indgrp =  lambda x: pd.Categorical(x['MJIND'].map(ind_codes))\n",
    "\n",
    "# Manager\n",
    "manager = lambda x: np.where(x.DTOCC == 1, 1,\n",
    "                    np.where(x.DTOCC > 0, 0, None))\n",
    "\n",
    "# Unemployment type recode - FIX (MAP IS SLOW)\n",
    "unemptype_map = {1: 'Job Loser', 2: 'Job Loser',\n",
    "                 3: 'Job Leaver',\n",
    "                 4: 'Re-entrant',\n",
    "                 5: 'New Entrant'}\n",
    "\n",
    "unemptype = lambda x: x['UNTYPE'].map(unemptype_map)\n",
    "\n",
    "# Layoff vs looking\n",
    "layoff = lambda x: pd.Categorical(\n",
    "    np.where(x['LFSR'] == 4, 'Layoff',\n",
    "    np.where(x['LFSR'] == 3, 'Looking', None)))\n",
    "\n",
    "# Part-time for economic reasons\n",
    "ptecon = lambda x: pd.Categorical(\n",
    "    np.where(x['WKSTAT'].isin([3, 5]), 1, \n",
    "    np.where(x['WKSTAT'].between(2, 5), 0, None)))\n",
    "\n",
    "# Worked full-time (usually FT or usually PT)\n",
    "workft = lambda x: pd.Categorical(\n",
    "    np.where(x['WKSTAT'] == 2, 1,\n",
    "    np.where(x['WKSTAT'].between(2, 5), 0, None)))\n",
    "\n",
    "# Usually work full-time (35+ hours)\n",
    "uslft = lambda x: pd.Categorical(\n",
    "    np.where((x['USLFT'] == 1) | (x['USLHRS'] >= 35), 1, \n",
    "    np.where(x['USLFT'] == 2, 0, None)))\n",
    "\n",
    "# Not at work during reference week\n",
    "notatwork = lambda x: pd.Categorical(\n",
    "    np.where(x['EMPHRS'].isin([1, 2, 3, 4, 5]), 1,\n",
    "    np.where(x['EMPHRS'].between(6, 16), 0, None)))\n",
    "\n",
    "# Map WBHAO codes for race/ethnicity\n",
    "hisp_map = cpsdd['jan94_mar94_dd.txt']['map']['hisp']\n",
    "hispanic = lambda x: pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 1, 0))\n",
    "race_map = cpsdd['jan94_mar94_dd.txt']['map']['race']\n",
    "wbhao = lambda x: (    # If not hispanic, map race to racial groups\n",
    "    pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 'Hispanic', \n",
    "                            x['RACE'].map(race_map))))\n",
    "wbao = lambda x: pd.Categorical(x['RACE'].map(race_map))\n",
    "\n",
    "# Wage variables\n",
    "wkearn = lambda x: np.where(x.WERNTP >= 0, x.WERNTP, None)\n",
    "hrwage = lambda x: np.where((x.HERNTP < 0) & (x.USLHRS > 0 ) & \n",
    "                            (x.WERNTP > 0), (x.WERNTP / x.USLHRS) / 100, \n",
    "                            np.where(x.HERNTP >= 0, x.HERNTP / 100, None)) \n",
    "priceadj = lambda x: 1 * x.REGION.map(cpi_vals)\n",
    "\n",
    "# Union member and coverage\n",
    "union = lambda x: pd.Categorical(\n",
    "    np.where((x['UNMEM'] == 1) | (x['UNCOV'] == 1), 1, \n",
    "    np.where((x['UNMEM'] == 2) & (x['UNCOV'] == 2), 0, None)),\n",
    "    ordered=True)\n",
    "unionmem = lambda x: pd.Categorical(\n",
    "    np.where(x['UNMEM'] == 1, 1, \n",
    "    np.where(x['UNMEM'] == 2, 0, None)),\n",
    "    ordered=True)\n",
    "\n",
    "# Paid hourly\n",
    "paidhrly = lambda x: pd.Categorical(\n",
    "    np.where(x['HRLYWK'] == 1, 1,\n",
    "    np.where(x['HRLYWK'] == 2, 0, None)))\n",
    "\n",
    "# bd CPS consistent variables\n",
    "age = lambda x: np.where(x['AGE'] > 80, 80, x['AGE'])\n",
    "female = lambda x: np.where(x['SEX'] == 2, 1, 0)\n",
    "faminc = lambda x: pd.Categorical(np.where(x.FAMINC.between(0, 14), \n",
    "                                           x.FAMINC + 1, None))\n",
    "veteran = lambda x: np.where(x['VET'].isin([1, 2, 3, 4, 5]), 1,\n",
    "                             np.where(x['VET'] == 6, 0, None))\n",
    "married = lambda x: np.where(x['MARITL'].isin([1, 2, 3]), 1, \n",
    "                             np.where(x['MARITL'].isin([4,5,6,7]), 0, None))\n",
    "emp = lambda x: np.where(x['LFSR'].isin([1,2]), 1, 0)\n",
    "\n",
    "# Labor force status\n",
    "lfs = lambda x: pd.Categorical(\n",
    "    np.where(x['LFSR'].isin([1, 2]), 'Employed',\n",
    "    np.where(x['LFSR'].isin([3, 4]), 'Unemployed',\n",
    "    np.where(x['LFSR'].isin([5, 6, 7]), 'NILF', None))))\n",
    "\n",
    "# Class of worker\n",
    "cow1 = lambda x: pd.Categorical(\n",
    "    np.where(x['CLSWKR'] == 2, 'Federal Government',\n",
    "    np.where(x['CLSWKR'] == 3, 'State Government',\n",
    "    np.where(x['CLSWKR'] == 4, 'Local Government',\n",
    "    np.where(x['CLSWKR'] == 1, 'Private',\n",
    "    np.where(x['CLSWKR'] == 5, 'Self-employed Incorporated',\n",
    "    np.where(x['CLSWKR'] == 6, 'Self-employed Unincorporated',\n",
    "    np.where(x['CLSWKR'] == 7, 'Without Pay', None))))))))\n",
    "\n",
    "\n",
    "# Weight variables\n",
    "basicwgt = lambda x: np.where(x['FNLWGT'] > 0, x['FNLWGT'] / 100.0, x['FNLWGT'])\n",
    "pworwgt = lambda x: np.where(x['ERNLWT'] > 0, x['ERNLWT'] / 100.0, x['ERNLWT'])\n",
    "hhwgt = lambda x: np.where(x['HHWGT'] > 0, x['HHWGT'] / 100.0, x['HHWGT'])\n",
    "\n",
    "# Read in Consumer Price Index data created by bd_CPS_cpi.ipynb\n",
    "cpi = pd.read_csv('clean/cpi.csv', index_col=[0], parse_dates=True)\n",
    "\n",
    "# Read data dictionaries for information on processing raw data files\n",
    "for ddf, year_list in dd_files.items():\n",
    "    \n",
    "    d = data_dict_reader(ddf, var_list)\n",
    "\n",
    "    dtypes = [(k, v[-1]) for k, v in d.items()]\n",
    "\n",
    "    unpacker = struct_unpacker(d)\n",
    "\n",
    "    # Loop over and process each monthly file in each year\n",
    "    for year in year_list:\n",
    "        file_list = [file for file in os.listdir()\n",
    "                     if file.endswith(f'{str(year)[2:]}pub.dat')]        \n",
    "        combined_data = []\n",
    "        \n",
    "        for file in file_list:\n",
    "            date = pd.to_datetime(f'{year}-{file[:3]}-01')\n",
    "            cpi_vals = cpi.loc[date].to_dict()\n",
    "            df = data_file_reader(file, unpacker, dtypes, filter_wgt)\n",
    "            df = df.rename(rename_list, axis=1)\n",
    "            # Education variable underlying data changes in 1992\n",
    "            if year < 1992:\n",
    "                # HGCI: Imputed Highest Grade Completed (Jaeger 2002)\n",
    "                # Pre-1992: HGA = highest grade attended, HGC = completed (1=yes, 2=no)\n",
    "                # If completed (HGC=1): HGCI = HGA\n",
    "                # If not completed (HGC=2): HGCI = HGA - 1\n",
    "                imphgc = np.where(df['HGC'] == 1,\n",
    "                                  df['HGA'],\n",
    "                                  np.where(df['HGC'] == 2,\n",
    "                                           df['HGA'] - 1,\n",
    "                                           df['HGA']))  # Default if HGC missing\n",
    "                df['HGCI'] = np.clip(imphgc, 0, 18)\n",
    "\n",
    "                # EDUCDT: Map HGA to PEEDUCA-style categories for consistency with 1992+\n",
    "                # Note: Uses HGA (grade attended) rather than completed for category mapping\n",
    "                educdt_pre92 = {0: 31, 1: 32, 2: 32, 3: 32, 4: 32,\n",
    "                                5: 33, 6: 33, 7: 34, 8: 34,\n",
    "                                9: 35, 10: 36, 11: 37, 12: 39,\n",
    "                                13: 40, 14: 40, 15: 40, 16: 43,\n",
    "                                17: 44, 18: 46}\n",
    "                # Adjust for non-completion at key thresholds\n",
    "                educdt_code = np.where(\n",
    "                    (df['HGA'] == 12) & (df['HGC'] == 2), 38,  # 12th no diploma\n",
    "                    df['HGA'].map(educdt_pre92))\n",
    "                df['EDUCDT'] = pd.Categorical(\n",
    "                    pd.Series(educdt_code).map(EducDTMap))\n",
    "\n",
    "                # EDUC: Grouped education categories (uses HGA and HGC directly)\n",
    "                # Note: HGA=0 (no schooling) is included in LTHS\n",
    "                educ_map = {\n",
    "                    'LTHS': (df['HGA'].between(0, 11)) | ((df['HGA']==12) & \n",
    "                                                          (df['HGC']==2)),\n",
    "                    'HS': (df['HGA']==12) & (df['HGC']==1),\n",
    "                    'SC': (df['HGA'].between(13,15)) | ((df['HGA']==16) & \n",
    "                                                        (df['HGC']==2)),\n",
    "                    'COLL': ((df['HGA']==16) & (df['HGC']==1)) | (df['HGA']==17),\n",
    "                    'ADV': (df['HGA'] >= 18)}\n",
    "                df['EDUC'] = (np.select(educ_map.values(), \n",
    "                                        educ_map.keys(), \n",
    "                                        default=None))\n",
    "                df = df.drop(['HGA', 'HGC'], axis=1)\n",
    "            # Add custom variables defined above\n",
    "            if year >= 1992:\n",
    "                # HGCI: Simple linearization from PEEDUCA-style codes (same as 1994-1997)\n",
    "                simple_map = {31: 0, 32: 2.5, 33: 5.5, 34: 7.5, 35: 9, 36: 10, 37: 11,\n",
    "                              38: 12, 39: 12, 40: 13, 41: 14, 42: 14, 43: 16, 44: 18, 45: 18, 46: 18}\n",
    "                df['HGCI'] = df['HGA'].map(simple_map)\n",
    "                df = df.assign(EDUC = educ, EDUCDT = educdt).drop(['HGA'], axis=1)\n",
    "            df = (df.assign(STATE = state,\n",
    "                            REGION = region,\n",
    "                            METSTAT = metstat,\n",
    "                            MPCSTAT = mpcstat,\n",
    "                            FAMINC = faminc,\n",
    "                            AGE = age,\n",
    "                            FEMALE = female,\n",
    "                            WBHAO = wbhao,\n",
    "                            WBAO = wbao,\n",
    "                            HISPANIC = hispanic,\n",
    "                            VETERAN = veteran,\n",
    "                            SCHENR = schenr,\n",
    "                            SCHOOL = school,\n",
    "                            MARRIED = married,\n",
    "                            EMP = emp,\n",
    "                            LFS = lfs,\n",
    "                            COW1 = cow1,\n",
    "                            UNEMPTYPE = unemptype,\n",
    "                            LAYOFF = layoff,\n",
    "                            PTECON = ptecon,\n",
    "                            WORKFT = workft,\n",
    "                            USLFT = uslft,\n",
    "                            NOTATWORK = notatwork,\n",
    "                            UNION = union,\n",
    "                            UNIONMEM = unionmem,\n",
    "                            PAIDHRLY = paidhrly,\n",
    "                            INDGRP = indgrp,\n",
    "                            MANAGER = manager,\n",
    "                            WKEARN = wkearn,\n",
    "                            HRWAGE = hrwage,\n",
    "                            PRICEADJ = priceadj,\n",
    "                            BASICWGT = basicwgt,\n",
    "                            PWORWGT = pworwgt,\n",
    "                            HHWGT = hhwgt)\n",
    "                    .drop(['STATEFIPS', 'SEX', 'VET', 'MARITL', 'UNTYPE',\n",
    "                           'REORGN', 'ENRLW', 'WKSTAT', 'UNMEM', 'RACE',\n",
    "                           'UNCOV', 'CLSWKR', 'HRLYWK', 'HERNTP', 'EMP',\n",
    "                           'WERNTP', 'LFSR', 'FNLWGT', 'ERNLWT', 'EMPHRS',\n",
    "                           'FTPT', 'HSCOL', 'HHNUM', 'METSTA',\n",
    "                           'MSAS'], axis=1))\n",
    "            df['YEAR'] = year\n",
    "            \n",
    "            # Rename and resize selected variables\n",
    "            df = df.rename({'USLHRS': 'HRSUSL1', 'HRS1': 'HRSACTT',\n",
    "                            'ID': 'HHID',\n",
    "                            'DTIND': 'IND80D', 'DTOCC': 'OCC80D',\n",
    "                            'MJIND': 'IND80M', 'MJOCC': 'OCC80M'}, axis=1)\n",
    "            if year < 1992:\n",
    "                df = df.rename({'IND': 'IND80', 'OCC': 'OCC80'}, axis=1)\n",
    "            if year >= 1992:\n",
    "                df = df.rename({'IND': 'IND90', 'OCC': 'OCC90'}, axis=1)\n",
    "            resize_vars = ['STATE', 'FEMALE', 'VETERAN', 'MARRIED', \n",
    "                           'EDUC', 'UNEMPTYPE', 'REGION', 'YEAR', 'PTECON',\n",
    "                           'CMSA', 'MSA']\n",
    "            df[resize_vars] = df[resize_vars].astype('category')\n",
    "            flt_vars = ['WKEARN', 'HRWAGE',\n",
    "                        'BASICWGT', 'PWORWGT', 'HHWGT']\n",
    "            df[flt_vars] = df[flt_vars].astype('float32')\n",
    "            \n",
    "            # Convert HGCI to ordered categorical for space efficiency\n",
    "            imphgc_cats = [0, 1, 2, 2.5, 3, 4, 5, 5.5, 6, 7, 7.5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "            df['HGCI'] = pd.Categorical(df['HGCI'], categories=imphgc_cats, ordered=True)\n",
    "            \n",
    "            # Add QSTNUM and OCCURNUM\n",
    "            df['QSTNUM'] = df.groupby('HHID').ngroup().astype('int32')\n",
    "            df['OCCURNUM'] = ((df.groupby('QSTNUM').cumcount() + 1)\n",
    "                                 .astype('int8'))\n",
    "            \n",
    "            # Major industry recode\n",
    "            for indvar in ['IND80', 'IND90']:\n",
    "                if indvar in df.keys():\n",
    "                    indmap = {i: k for k, v in INDMMap.items() for i in v[indvar]}\n",
    "                    indm = lambda x: pd.Categorical(x[indvar].map(indmap))\n",
    "                    df = df.assign(INDM = indm)\n",
    "            \n",
    "            # Broad industry group recode - consistent over years\n",
    "            # Fixes leisure/hospitality discontinuity using detailed industry codes\n",
    "            if 'IND80' in df.columns:\n",
    "                indgrpmap = {i: k for k, v in INDGRPMap.items() for i in v['IND80']}\n",
    "                df['INDGRP'] = pd.Categorical(df['IND80'].map(indgrpmap))\n",
    "            elif 'IND90' in df.columns:\n",
    "                indgrpmap = {i: k for k, v in INDGRPMap.items() for i in v['IND90']}\n",
    "                df['INDGRP'] = pd.Categorical(df['IND90'].map(indgrpmap))\n",
    "            \n",
    "            # bd CPS household ID\n",
    "            if os.path.isfile(ids_file):\n",
    "                df['CPSID'] = df['QSTNUM'].map(cps_ids_full[date])\n",
    "\n",
    "            combined_data.append(df)\n",
    "            \n",
    "        # Combine monthly files into annual file\n",
    "        df = (pd.concat(combined_data)).reset_index(drop=True)\n",
    "        \n",
    "        ind_occ_cats = ['INDGRP', 'IND80', 'OCC80', 'IND80D', 'OCC80D',\n",
    "                        'IND80M', 'OCC80M', 'IND90', 'OCC90']\n",
    "        cat_vars = [cv for cv in ind_occ_cats if cv in df.keys()]\n",
    "        convert_dict = {cat: 'category' for cat in cat_vars}\n",
    "        df = df.astype(convert_dict)       \n",
    "        \n",
    "        # Store results as feather file\n",
    "        df.to_feather(f'clean/cps{year}.ft')\n",
    "        \n",
    "        # Print outcome\n",
    "        obs = len(df)\n",
    "        cols = len(df.keys())\n",
    "        size = round(df.memory_usage().sum() / 1024**2, 1)\n",
    "        print(f'{year} Done: ({obs:,} records, {cols} variables, {size}MB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}