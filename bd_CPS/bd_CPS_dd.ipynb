{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS data dictionaries\n",
    "\n",
    "bd_CPS_dd.ipynb\n",
    "\n",
    "April 14, 2019\n",
    "\n",
    "@bd_econ\n",
    "\n",
    "Requires: `cps_details.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:47:39.303976Z",
     "start_time": "2024-06-18T14:47:39.067550Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-08-05T11:42:22.985819Z",
     "iopub.status.busy": "2025-08-05T11:42:22.985141Z",
     "iopub.status.idle": "2025-08-05T11:42:23.299696Z",
     "shell.execute_reply": "2025-08-05T11:42:23.299189Z",
     "shell.execute_reply.started": "2025-08-05T11:42:22.985750Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:65: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join([x for x in VarList if x not in LostVars])})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:68: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join([x for x in VarList if x not in LostVars])})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:71: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:74: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:77: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:80: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:83: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:86: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:89: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:92: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'({\"|\".join(VarList)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:95: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:98: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:101: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:104: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:107: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:110: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:113: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  're': 'D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:116: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  're': 'D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:119: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:122: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:125: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n",
      "/home/brian/Documents/econ_data/bd_CPS/bd_CPS_details.py:128: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  're': f'\\n(?:\\x0c)?({\"|\".join(VarList)})\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'},\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import pickle\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "\n",
    "from bd_CPS_details import VarList, DataDict, text_repl, StatesMap, RegionsMap\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')\n",
    "\n",
    "# Some variables start in the middle of the jan98dd.asc dictionary\n",
    "# This code splits the jan98dd.asc into two\n",
    "ddf = open('jan98dd.asc', 'r', encoding='iso-8859-1').read()\n",
    "chldvars = 'PRPERTYP \\n     = 2 \\n\\nD PRCHLD    2    633\\n\\nD PRNMCHLD    2    635\\n'\n",
    "ddf = ddf.replace('PRPERTYP \\n     = 2 ', chldvars)\n",
    "with open('jan98dd2.asc', \"w\") as ddm:\n",
    "    ddm.write(ddf)\n",
    "    \n",
    "# Fix two typos in latest data dictionary\n",
    "file = '2020_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt'\n",
    "ddf = open(file, 'r', encoding='iso-8859-1').read()\n",
    "ddf = (ddf.replace('PRSJMS\\t\\t\\t', 'PRSJMS\\t\\t\\t2')\n",
    "          .replace('PRNAGWS\\t\\t\\t', 'PRNAGWS\\t\\t\\t2'))\n",
    "with open('January_2020_Record_Layout.txt', 'w') as ddm:\n",
    "    ddm.write(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:47:39.406509Z",
     "start_time": "2024-06-18T14:47:39.308936Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-08-05T11:42:23.300659Z",
     "iopub.status.busy": "2025-08-05T11:42:23.300419Z",
     "iopub.status.idle": "2025-08-05T11:42:23.402096Z",
     "shell.execute_reply": "2025-08-05T11:42:23.401576Z",
     "shell.execute_reply.started": "2025-08-05T11:42:23.300643Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\('\n",
      "/tmp/ipykernel_421960/4279631871.py:16: SyntaxWarning: invalid escape sequence '\\('\n",
      "  dvals['re'].replace('(partII)', '\\(partII\\)'), ddf)}\n"
     ]
    }
   ],
   "source": [
    "# Match CPS microdata files with their data dictionary\n",
    "Matcher = {}\n",
    "\n",
    "DataDict.pop('matcher', None)\n",
    "for dfile, dvals in DataDict.items():\n",
    "    #print(dfile)\n",
    "    ddf = open(f'{dfile}', 'r', encoding='iso-8859-1').read()\n",
    "    if dfile in ['jan03dd.txt', 'augnov05dd.txt', 'jan07dd.txt']:\n",
    "        ddf = ddf.replace('PRNMCHLD', 'PRNMCHLD  2  ')\n",
    "    if dfile in ['jan98dd.asc', 'jan98dd2.asc']:\n",
    "        d = {text_repl(s[0]): [int(s[2])-1, int(s[2])+int(s[1])-1, int(s[1])] \n",
    "             for s in re.findall(dvals['re'], ddf) if s[0] in VarList}       \n",
    "    elif dfile == 'may04dd.txt':\n",
    "        d = {text_repl(s[0]): [int(s[2])-1, int(s[3]), int(s[1])] \n",
    "             for s in re.findall(\n",
    "                 dvals['re'].replace('(partII)', '\\(partII\\)'), ddf)}\n",
    "    else:\n",
    "        d = {text_repl(s[0]): [int(s[3])-1, int(s[4]), int(s[2])] \n",
    "             for s in re.findall(dvals['re'], ddf)}\n",
    "    \n",
    "    # Suggest dtypes for numpy\n",
    "    for k, v in d.items(): \n",
    "        d[k].append('U4' if k in ['HRSAMPLE']\n",
    "                    else 'U2' if k in ['HRSERSUF']\n",
    "                    else 'int32' if k in ['GTCO', 'GESTFIPS']\n",
    "                    #else 'int64' if k in ['HRHHID2']\n",
    "                    else 'f4' if 'WGT' in k\n",
    "                    else 'int8' if v[-1] < 3 \n",
    "                    else 'int16' if v[-1] < 5 \n",
    "                    else 'int32' if v[-1] < 11 \n",
    "                    else 'intp')    \n",
    "    \n",
    "    # Make sure that start and end = length\n",
    "    error_list = [k for k, v in d.items() if v[1] - v[0] != v[2]]\n",
    "    if len(error_list) > 0:\n",
    "        print(f'Error: {dfile}: {\", \".join(error_list)}')\n",
    "    DataDict[dfile]['dd'] = d\n",
    "    \n",
    "    # Add list of related monthly CPS microdata files\n",
    "    mos = pd.date_range(dvals['start'], dvals['end'], freq='MS')\n",
    "    monthly_file_list = [f'{i:%b%y}pub.dat'.lower() for i in mos]\n",
    "    DataDict[dfile]['flist'] = monthly_file_list\n",
    "    \n",
    "    # Add relevant monthly CPS filenames to matcher\n",
    "    for file in monthly_file_list:\n",
    "        Matcher[file] = dfile\n",
    "    \n",
    "    # Stuct unpack format\n",
    "    start, end, width, fmt = zip(*d.values())\n",
    "    skip = ([f'{st - en}x' if (st - en) > 0 else '' \n",
    "             for st, en in zip(start, [0] + list(end[:-1]))])\n",
    "    keep = [f'{w}s' for w in width]\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, keep) for j in i])\n",
    "    DataDict[dfile]['unpack_fmt'] = unpack_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:47:39.433798Z",
     "start_time": "2024-06-18T14:47:39.407837Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-08-05T11:42:23.405049Z",
     "iopub.status.busy": "2025-08-05T11:42:23.404842Z",
     "iopub.status.idle": "2025-08-05T11:42:23.463115Z",
     "shell.execute_reply": "2025-08-05T11:42:23.462178Z",
     "shell.execute_reply.started": "2025-08-05T11:42:23.405032Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Create new/cleaned variables\n",
    "# Education groups\n",
    "educ = {'LTHS': [31, 32, 33, 34, 35, 36, 37, 38], \n",
    "        'HS': [39],\n",
    "        'SC': [40, 41, 42],\n",
    "        'COLL': [43],\n",
    "        'ADV': [44, 45, 46]}\n",
    "educ_map = {}\n",
    "for k, v in educ.items():\n",
    "    for i in v:\n",
    "        educ_map.update({i:k})\n",
    "\n",
    "for dfile, dvals in DataDict.items():\n",
    "    DataDict[dfile]['map'] = {}\n",
    "    \n",
    "    # Add state id map to two letter codes\n",
    "    DataDict[dfile]['map']['state'] = StatesMap\n",
    "    \n",
    "    # Add Census regions map from state two letter codes\n",
    "    DataDict[dfile]['map']['region'] = RegionsMap\n",
    "    \n",
    "    # Add education groups\n",
    "    DataDict[dfile]['map']['educ'] = educ_map\n",
    "    \n",
    "    # WBHAO and WBHAOM race/ethnic groups from CEPR\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2012-04-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 16, 17, 18, 22, 23], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 15, 19, 20, 21, 24], \n",
    "                'Other': [3, 7, 25, 26]}\n",
    "        racem = {'White': [1],\n",
    "                 'Black': [2],\n",
    "                 'Asian': [4, 5],\n",
    "                 'Native American': [3],\n",
    "                 'More than one': list(range(6, 27))}\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 15, 16, 19], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 17, 18], \n",
    "                'Other': [3, 7, 20, 21]}\n",
    "        racem = {'White': [1],\n",
    "                 'Black': [2],\n",
    "                 'Asian': [4, 5],\n",
    "                 'Native American': [3],\n",
    "                 'More than one': list(range(6, 22))}\n",
    "    else:  # Mixed not available before 2003\n",
    "        race = {'White': [1], \n",
    "                'Black': [2], \n",
    "                'Asian': [4], \n",
    "                'Other': [3, 5]}\n",
    "    race_map = {i: k for k, v in race.items() for i in v}\n",
    "    race_map2 = {i: k for k, v in racem.items() for i in v}\n",
    "    DataDict[dfile]['map']['race'] = race_map\n",
    "    DataDict[dfile]['map']['racem'] = race_map2    \n",
    "    \n",
    "    # Hispanic identification\n",
    "    if start_month > pd.to_datetime('2013-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        hispdt = {'Mexican': [1],\n",
    "                  'Puerto Rican': [2],\n",
    "                  'Cuban': [3],\n",
    "                  'Dominican': [4],\n",
    "                  'Salvadoran': [5],\n",
    "                  'Central American, excluding Salvadoran': [6],\n",
    "                  'Sotuh American': [7],\n",
    "                  'Other Spanish': [8]}\n",
    "        hispdt03 = {'Mexican': [1],\n",
    "                    'Puerto Rican': [2],\n",
    "                    'Cuban': [3],\n",
    "                    'Central/South American': [4, 5, 6, 7],\n",
    "                    'Other Spanish': [8]}\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5]\n",
    "        hispdt03 = {'Mexican': [1],\n",
    "                    'Puerto Rican': [2],\n",
    "                    'Cuban': [3],\n",
    "                    'Central/South American': [4],\n",
    "                    'Other Spanish': [5]}\n",
    "    else:\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7]\n",
    "        \n",
    "    hisp_map = {i: k for k, v in hispdt.items() for i in v}\n",
    "    hisp_map2 = {i: k for k, v in hispdt03.items() for i in v}\n",
    "    DataDict[dfile]['map']['hisp'] = hisp\n",
    "    DataDict[dfile]['map']['hispdt'] = hisp_map\n",
    "    DataDict[dfile]['map']['hispdt03'] = hisp_map2\n",
    "    \n",
    "    # Major industry group\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2002-12-01'):\n",
    "        ind = {'Construction and mining': [1, 2, 3],\n",
    "               'Finance and business services': [7, 8, 9, 12],\n",
    "               'Manufacturing': [4],\n",
    "               'Trade, transportation, and utilities': [5, 6],\n",
    "               'Education and health': [10],\n",
    "               'Leisure and hospitality': [11],\n",
    "               'Public administration': [13],\n",
    "               'Armed forces': [14]}\n",
    "    else:\n",
    "        ind = {'Construction and mining': [1, 2, 3, 21],\n",
    "               'Finance and business services': [7, 11, 12, 13, 14, 20],\n",
    "               'Manufacturing': [4, 5],\n",
    "               'Trade, transportation, and utilities': [6, 8, 9, 10],\n",
    "               'Education and health': [16, 17, 18, 19],\n",
    "               'Leisure and hospitality': [15],\n",
    "               'Public administration': [22],\n",
    "               'Armed forces': [23]}    \n",
    "    ind_map = {i: k for k, v in ind.items() for i in v}    \n",
    "    DataDict[dfile]['map']['ind'] = ind_map     \n",
    "    \n",
    "    # Broader EPI version of Major industry group\n",
    "    \n",
    "        \n",
    "    # Identify when to calculate ID2 manually\n",
    "    DataDict[dfile]['map']['id2'] = False\n",
    "    if start_month < pd.to_datetime('2004-05-01'):\n",
    "        DataDict[dfile]['map']['id2'] = True\n",
    "\n",
    "    # Identify weight variables for each data dict\n",
    "    wgt_vars = [i for i in dvals['dd'].keys() if 'WGT' in i]\n",
    "    DataDict[dfile]['map']['wgt'] = wgt_vars\n",
    "\n",
    "    # Identify earnings variables for each data dict\n",
    "    er_vars = [i for i in dvals['dd'].keys() if 'PRER' in i]\n",
    "    DataDict[dfile]['map']['er'] = er_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:47:39.439441Z",
     "start_time": "2024-06-18T14:47:39.435499Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2025-08-05T11:42:23.463732Z",
     "iopub.status.busy": "2025-08-05T11:42:23.463569Z",
     "iopub.status.idle": "2025-08-05T11:42:23.467871Z",
     "shell.execute_reply": "2025-08-05T11:42:23.467323Z",
     "shell.execute_reply.started": "2025-08-05T11:42:23.463716Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate pickle file with data for reader\n",
    "DataDict['matcher'] = Matcher\n",
    "\n",
    "with open('cps_basic_dd.pkl', 'wb') as f:\n",
    "    pickle.dump(DataDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
